from bs4 import BeautifulSoup
import pandas as pd
# from pyecharts.charts import Scatter
from tqdm import tqdm
import math
import requests
import lxml
import re
import time
import os
# from pyecharts.charts import Scatter
# from pyecharts import options as opts

# åŒºå
districtName = 'è¶Šç§€åŒº'
area_dic = {
            districtName :'yuexiu'
            # 'å¤©å®åŒº':'tianningqu',
            # 'é’Ÿæ¥¼åŒº':'zhonglouqu',
            # 'æ–°åŒ—åŒº':'xinbeiqu',
            # 'æ­¦è¿›åŒº':'wujinqu',
            # 'é‡‘å›åŒº':'jintanqu'
            }

# ä¿å­˜æ–‡ä»¶å
outputFilename = districtName + 'ç§Ÿæˆ¿'

# åŠ ä¸ªheaderä»¥ç¤ºå°Šæ•¬
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
            'Referer': 'https://gz.lianjia.com/zufang/yuexiu/'}

# æ–°å»ºä¸€ä¸ªä¼šè¯
sess = requests.session()
sess.get(headers['Referer'], headers=headers)

# urlç¤ºä¾‹ï¼šhttps://sz.lianjia.com/ershoufang/luohuqu/pg2/
url = headers['Referer'] + "pg{}/#contentlist"

# å½“æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¤±è´¥æ—¶ï¼Œè¿”å›é»˜è®¤å€¼ï¼ˆerrifï¼‰
def re_match(re_pattern, string, errif=None):
    try:
        return re.findall(re_pattern, string)[0].strip()
    except IndexError:
        return errif

# æ–°å»ºä¸€ä¸ªDataFrameå­˜å‚¨ä¿¡æ¯
data = pd.DataFrame()

for key_, value_ in area_dic.items():
    # è·å–è¯¥è¡Œæ”¿åŒºä¸‹æˆ¿æºè®°å½•æ•°
    start_url = headers['Referer'] + '{}/'.format(value_)
    html = sess.get(start_url).text
    house_num = re.findall('<span class="content__title--hl">(.*?)</span>', html)[0].strip()
    # new web: <span class="content__title--hl">5208</span>
    # old web: <span> 9527 </span>
    print('ğŸ’š{}: ç§Ÿæˆ¿æˆ¿æºå…±è®¡ã€Œ{}ã€å¥—'.format(key_, house_num))
    time.sleep(1)
    # é¡µé¢é™åˆ¶ğŸš« æ¯ä¸ªè¡Œæ”¿åŒºåªèƒ½è·å–æœ€å¤š100é¡µå…±è®¡3000æ¡æˆ¿æºä¿¡æ¯
    total_page = int(math.ceil(min(3000, int(house_num)) / 30.0))
    for i in tqdm(range(total_page), desc=key_):
        # wait forever to avoid network issue
        while True:
            html = sess.get(url.format(i+1)).text
            soup = BeautifulSoup(html, 'lxml')
            info_collect = soup.find_all(class_="content__list--item--main")
            if len(info_collect):
                break
        for info in info_collect:
            info = str(info).replace('\n', '')
            info_dic = {}
            # æˆ¿æºçš„æ ‡é¢˜
            info_dic['title'] = re_match('<a class="twoline" href.*?target="_blank">(.*?)</a>', str(info))
            if info_dic['title'] is None:
                info_dic['title'] = re_match('<a href=.*?target="_blank">(.*?)</a>', str(info))
            ########### info des ###########
            info_des = re_match('<p class="content__list--item--des">(.*?)</p>', str(info))
            info_des_pos = re_match('<a href=.*?target="_blank">(.*?)</a><i>', info_des)
            if info_des_pos:
                # è¡Œæ”¿åŒº
                info_dic['area'] = re_match('(.*?)</a>-<a', info_des_pos)
                # ä½ç½®
                info_dic['position'] = re_match('</a>-<a href=.*?target="_blank">(.*?)</a>', info_des_pos)
                # å°åŒº
                info_dic['community'] = info_des_pos.split('>')[-1]
            else:
                # å‰©ä½™æˆ¿å±‹
                info_dic['room left'] = re_match('<span class="room__left">(.*?)</span>', info_des)
            info_des_i = re_match('<i>/</i>(.*?)</span>', info_des)
            if info_des_i:
                info_des_output = re.split('<i>/</i>', info_des_i)
                # é¢ç§¯
                info_dic['size'] = info_des_output[0].strip()
                # æœå‘
                info_dic['orientation'] = info_des_output[1].strip()
                # æˆ¿é—´
                info_dic['room'] = re.split('<span class="hide">', info_des_output[2])[0].strip()
                # æ¥¼å±‚
                info_dic['floor'] = info_des_output[3].replace(' ', '')
            ########### info bottom oneline ###########
            info_bottom = re_match('<p class="content__list--item--bottom oneline">(.*?)</p>', str(info)).replace('\n', '')
            info_bottom_output = re.split('<i class="content__item__tag--', info_bottom)
            for infoIndex in range(1, len(info_bottom_output)):
                tag = info_bottom_output[infoIndex].split('">')[0]
                info_dic[tag] = info_bottom_output[infoIndex].split('">')[1].split('</i>')[0]
            ########### info brand oneline ###########
            info_brand = re_match('<p class="content__list--item--brand oneline">(.*?)</p>', str(info)).replace(' ', '')
            info_dic['brand'] = re_match('<spanclass="brand">(.*?)</span>', info_brand)
            info_dic['time online'] = re_match('<spanclass="content__list--item--timeoneline">(.*?)</span>', info_brand)

            # æœˆç§Ÿ
            info_dic['price'] = re_match('<span class="content__list--item-price"><em>(.*?)</em>', str(info))
            # å­˜å…¥DataFrame
            if data.empty:
                data = pd.DataFrame(info_dic, index=[0])
            else:
                data = pd.concat([data, pd.DataFrame([info_dic])], ignore_index=True)

if not data.empty:
    data.to_excel(os.path.join('./data', outputFilename + '.xlsx'), index=False)

