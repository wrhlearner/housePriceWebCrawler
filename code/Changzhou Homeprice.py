from bs4 import BeautifulSoup
import pandas as pd
from pyecharts.charts import Scatter
from tqdm import tqdm
import math
import requests
import lxml
import re
import time
from pyecharts.charts import Scatter
from pyecharts import options as opts

area_dic = {
            # 'è”æ¹¾åŒºäºŒæ‰‹':'liwanershou'
            # 'è¶Šç§€åŒºäºŒæ‰‹':'yuexiuershou'
            # 'è”æ¹¾åŒº':'liwanqu'
            # 'è¶Šç§€åŒº':'yuexiuqu'
            # 'é’Ÿæ¥¼åŒº':'zhonglouqu',
            # 'æ–°åŒ—åŒº':'xinbeiqu',
            # 'æ­¦è¿›åŒº':'wujinqu',
            # 'é‡‘å›åŒº':'jintanqu'
            }

# åŠ ä¸ªheaderä»¥ç¤ºå°Šæ•¬
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',
        # 'Referer': 'https://gz.lianjia.com/ershoufang/liwan/'}
        'Referer': 'https://gz.lianjia.com/ershoufang/yuexiu/'}
        # 'Referer': 'https://gz.fang.lianjia.com/loupan/liwan/'}
        # 'Referer': 'https://gz.fang.lianjia.com/loupan/liwan-yuexiu/#yuexiu/'}

# æ–°å»ºä¸€ä¸ªä¼šè¯
sess = requests.session()
# sess.get('https://gz.lianjia.com/ershoufang/liwan/', headers=headers)
sess.get('https://gz.lianjia.com/ershoufang/yuexiu/', headers=headers)
# sess.get('https://gz.fang.lianjia.com/loupan/liwan/', headers=headers)
# sess.get('https://gz.fang.lianjia.com/loupan/liwan-yuexiu/#yuexiu/', headers=headers)

# urlç¤ºä¾‹ï¼šhttps://sz.lianjia.com/ershoufang/luohuqu/pg2/
# url = 'https://gz.lianjia.com/ershoufang/liwan/{}/pg{}/'
url = 'https://gz.lianjia.com/ershoufang/yuexiu/{}/pg{}/'
# url = 'https://gz.fang.lianjia.com/loupan/liwan/{}/pg{}/'
# url = 'https://gz.fang.lianjia.com/loupan/liwan-yuexiu/#yuexiu/{}/pg{}/'

# å½“æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…å¤±è´¥æ—¶ï¼Œè¿”å›é»˜è®¤å€¼ï¼ˆerrifï¼‰
def re_match(re_pattern, string, errif=None):
    try:
        return re.findall(re_pattern, string)[0].strip()
    except IndexError:
        return errif

# æ–°å»ºä¸€ä¸ªDataFrameå­˜å‚¨ä¿¡æ¯
data = pd.DataFrame()

for key_, value_ in area_dic.items():
    # è·å–è¯¥è¡Œæ”¿åŒºä¸‹æˆ¿æºè®°å½•æ•°
    # start_url = 'https://gz.lianjia.com/ershoufang/liwan/{}/'.format(value_)
    start_url = 'https://gz.lianjia.com/ershoufang/yuexiu/{}/'.format(value_)
    # start_url = 'https://gz.fang.lianjia.com/loupan/liwan/{}/'.format(value_)
    # start_url = 'https://gz.fang.lianjia.com/loupan/liwan-yuexiu/#yuexiu/{}/'.format(value_)
    html = sess.get(start_url).text
    house_num = re.findall('å…±æ‰¾åˆ°<span> (.*?) </span>å¥—.*äºŒæ‰‹æˆ¿', html)[0].strip()
    print('ğŸ’š{}: äºŒæ‰‹æˆ¿æºå…±è®¡ã€Œ{}ã€å¥—'.format(key_, house_num))
    time.sleep(1)
    # é¡µé¢é™åˆ¶ğŸš« æ¯ä¸ªè¡Œæ”¿åŒºåªèƒ½è·å–æœ€å¤š100é¡µå…±è®¡3000æ¡æˆ¿æºä¿¡æ¯
    total_page = int(math.ceil(min(3000, int(house_num)) / 30.0))
    for i in tqdm(range(total_page), desc=key_):
        html = sess.get(url.format(value_, i+1)).text
        soup = BeautifulSoup(html, 'lxml')
        info_collect = soup.find_all(class_="info clear")

        for info in info_collect:
            info_dic = {}
            # è¡Œæ”¿åŒº
            info_dic['area'] = key_
            # æˆ¿æºçš„æ ‡é¢˜
            info_dic['title'] = re_match('target="_blank">(.*?)</a><!--', str(info))
            # å°åŒºå
            info_dic['community'] = re_match('xiaoqu.*?target="_blank">(.*?)</a>', str(info))
            # ä½ç½®
            info_dic['position'] = re_match('<a href.*?target="_blank">(.*?)</a>.*?class="address">', str(info))
            # ç¨ç›¸å…³ï¼Œå¦‚æˆ¿æœ¬æ»¡5å¹´
            info_dic['tax'] = re_match('class="taxfree">(.*?)</span>', str(info))
            # æ€»ä»·
            info_dic['total_price'] = re_match('class="totalPrice"><span>(.*?)</span>ä¸‡', str(info))
            # å•ä»·
            info_dic['unit_price'] = float(re_match('data-price="(.*?)"', str(info)))

            # åŒ¹é…æˆ¿æºæ ‡ç­¾ä¿¡æ¯ï¼Œé€šè¿‡|åˆ‡å‰²
            # åŒ…æ‹¬é¢ç§¯ï¼Œæœå‘ï¼Œè£…ä¿®ç­‰ä¿¡æ¯
            icons = re.findall('class="houseIcon"></span>(.*?)</div>', str(info))[0].strip().split('|')
            info_dic['hourseType'] = icons[0].strip()
            info_dic['hourseSize'] = float(icons[1].replace('å¹³ç±³', ''))
            info_dic['direction'] = icons[2].strip()
            info_dic['fitment'] = icons[3].strip()

            # å­˜å…¥DataFrame
            if data.empty:
                data = pd.DataFrame(info_dic, index=[0])
            else:
                data = pd.concat([data, pd.DataFrame([info_dic])], ignore_index=True)

if not data.empty:
    name = 'liwanershou'
    # districtName = 'yuexiuershou'
    # districtName = 'liwanqu'
    # districtName = 'yuexiuqu'
    filename = name + '.xlsx'
    data.to_excel(filename, index=False)

